levels = c("no", 'yes')) %>%
step_num2factor(portalHyper,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(portalVeinThromb,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(LiverMeta,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(RadioHallmark,transform = function(x) x + 1,
levels = c("no", 'yes'))
# %>%
#   step_num2factor(numNodules,transform = function(x) x + 1,
#                   levels = as.character(0:5))
dat2 <- bake(prep(rec_base), new_data = dat)
xgbtree_model <- TunedModel(XGBTreeModel,
grid = expand_params(
nrounds = as.integer(c(50, 100, 150)),
# number of boosting iterations
eta = seq(0.1, 0.5, length = 5),
# shrinkage of variable weights at each iteration to prevent overfitting
max_depth = as.integer(c(4:8))
# maximum tree depth
)
)
fnames <- paste0("./data/ModelCache/",
c("knn_none_xgboost_fit.RDS", "knn_none_xgboost_res.RDS"))
# remove predictor variables that have too many missing values by using step_nzv
# use knn to impute
# use bag to impute
rec_knn_none <- rec_base %>%
step_nzv(all_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors()) %>%
step_impute_knn(all_predictors(), id = "knn") %>%
# step_impute_mode(all_nominal_predictors()) %>%
# step_impute_mean(all_numeric_predictors())
rec_grid_knn_none <- expand_steps(
knn = list(neighbors = 1:5)
)
fnames <- paste0("./data/ModelCache/",
c("knn_none_xgboost_fit.RDS", "knn_none_xgboost_res.RDS"))
# remove predictor variables that have too many missing values by using step_nzv
# use knn to impute
# use bag to impute
rec_knn_none <- rec_base %>%
step_nzv(all_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors()) %>%
step_impute_knn(all_predictors(), id = "knn")
# step_impute_mode(all_nominal_predictors()) %>%
# step_impute_mean(all_numeric_predictors())
rec_grid_knn_none <- expand_steps(
knn = list(neighbors = 1:5)
)
rec_tun_knn_none <- TunedInput(rec_knn_none, grid = rec_grid_knn_none)
mspec_tun_knn_none <- ModelSpecification(
rec_tun_knn_none,
model = xgbtree_model,
control = ctrl
) %>% set_optim_bayes()
# use bayesian optimization
# get the optimal model selected
mlfit_knn_none <- fit(mspec_tun_knn_none)
integer(20)
dat <- readRDS("./data/hcc_data.RDS")
#dat <- readRDS("~/Desktop/R practice/Machine learning class spring 2022/hcc-survival/hcc_data.RDS")
rec_base <- recipe(
status ~ .,
data = dat
) %>%
role_case(stratum = status) %>%
check_missing(status) %>%
step_num2factor(status, transform = function(x) x + 1,
levels = c("died", "survive")) %>%
step_num2factor(gender, transform = function(x) x + 1,
levels = c("female", "male")) %>%
step_num2factor(symptom, transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(alc, transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepBsurfAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepBeAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepBcorAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepCvirAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(cirr,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(endemicCountries,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(smoke,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(diabetes,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(obese,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hemochro,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(artHyper,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(chronRenal,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hiv,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(Nasteato,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(esophVarices,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(spleno,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(portalHyper,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(portalVeinThromb,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(LiverMeta,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(RadioHallmark,transform = function(x) x + 1,
levels = c("no", 'yes'))
# %>%
#   step_num2factor(numNodules,transform = function(x) x + 1,
#                   levels = as.character(0:5))
dat2 <- bake(prep(rec_base), new_data = dat)
library(dplyr)
library(MachineShop)
library(recipes)
library(kableExtra)
library(arsenal)
library(doSNOW)
registerDoSNOW(makeCluster(8))
## Resample control object
ctrl <- CVControl(seed = 123)
dat <- readRDS("./data/hcc_data.RDS")
#dat <- readRDS("~/Desktop/R practice/Machine learning class spring 2022/hcc-survival/hcc_data.RDS")
rec_base <- recipe(
status ~ .,
data = dat
) %>%
role_case(stratum = status) %>%
check_missing(status) %>%
step_num2factor(status, transform = function(x) x + 1,
levels = c("died", "survive")) %>%
step_num2factor(gender, transform = function(x) x + 1,
levels = c("female", "male")) %>%
step_num2factor(symptom, transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(alc, transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepBsurfAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepBeAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepBcorAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hepCvirAnti,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(cirr,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(endemicCountries,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(smoke,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(diabetes,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(obese,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hemochro,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(artHyper,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(chronRenal,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(hiv,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(Nasteato,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(esophVarices,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(spleno,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(portalHyper,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(portalVeinThromb,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(LiverMeta,transform = function(x) x + 1,
levels = c("no", 'yes')) %>%
step_num2factor(RadioHallmark,transform = function(x) x + 1,
levels = c("no", 'yes'))
# %>%
#   step_num2factor(numNodules,transform = function(x) x + 1,
#                   levels = as.character(0:5))
dat2 <- bake(prep(rec_base), new_data = dat)
## Define RandomForest model and its tuning grid to be tuend simultaneously with recipe input later
grid.model <- TunedModel(RandomForestModel(),
grid = expand_params(
ntree = 500,
#number of trees to grow
mtry = 10,
#number of variables rnadomly sampled as caididates at each split
nodesize = 2,
#minimum size of terminal nodes
maxnodes = as.integer(20)
#maximum number of terminal nodes trees in the forest can have.
)
)
# remove predictor variables that have too many missing values by using step_nzv
# use knn to impute
# use bag to impute
rec_knn_none <- rec_base %>%
step_impute_knn(all_predictors(), id = "knn")  %>%
step_nzv(all_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors())
# step_impute_mode(all_nominal_predictors()) %>%
# step_impute_mean(all_numeric_predictors())
rec_grid_knn_none <- expand_steps(
knn = list(neighbors = 1:5)
)
rec_tun_knn_none <- TunedInput(rec_knn_none, grid = rec_grid_knn_none)
mspec_tun_knn_none <- ModelSpecification(
rec_tun_knn_none,
model = grid.model,
control = ctrl
) %>% set_optim_bayes()
# use bayesian optimization
# get the optimal model selected
mlfit_knn_none <- fit(mspec_tun_knn_none) #this gives error message of "error in usemethod ("fit"): no applicable method for 'fit applied to an object of class "ModelSpecification"
## Define RandomForest model and its tuning grid to be tuend simultaneously with recipe input later
grid.model <- TunedModel(RandomForestModel(),
grid = expand_params(
ntree = as.integer(c(50, 500)),
#number of trees to grow
mtry = as.integer(c(5, 10)),
#number of variables rnadomly sampled as caididates at each split
nodesize = 2,
#minimum size of terminal nodes
maxnodes = as.integer(5, 20)
#maximum number of terminal nodes trees in the forest can have.
)
)
# remove predictor variables that have too many missing values by using step_nzv
# use knn to impute
# use bag to impute
rec_knn_none <- rec_base %>%
step_impute_knn(all_predictors(), id = "knn")  %>%
step_nzv(all_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_center(all_predictors()) %>%
step_scale(all_predictors())
# step_impute_mode(all_nominal_predictors()) %>%
# step_impute_mean(all_numeric_predictors())
rec_grid_knn_none <- expand_steps(
knn = list(neighbors = 1:5)
)
rec_tun_knn_none <- TunedInput(rec_knn_none, grid = rec_grid_knn_none)
mspec_tun_knn_none <- ModelSpecification(
rec_tun_knn_none,
model = grid.model,
control = ctrl
) %>% set_optim_bayes()
# use bayesian optimization
