---
title: "XGBModel_YL"
author: "Yujing Lu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loadPackages, message=FALSE, warning=FALSE}
library(dplyr)
library(MachineShop)
library(recipes)
library(kableExtra)
library(arsenal)
```

```{r controlSetup, results='hide', echo=FALSE}
library(doSNOW)
registerDoSNOW(makeCluster(8))
## Resample control object
ctrl <- CVControl(seed = 123)
```

```{r rec_base, echo = FALSE}
dat <- readRDS("./data/hcc_data.RDS")

rec_base <- recipe(
  status ~ .,
  data = dat
) %>%
  role_case(stratum = status) %>%
  check_missing(status) %>%
  step_num2factor(status, transform = function(x) x + 1,
                  levels = c("died", "survive")) %>%
  step_num2factor(gender, transform = function(x) x + 1,
                  levels = c("female", "male")) %>%
  step_num2factor(symptom, transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(alc, transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepBsurfAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepBeAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepBcorAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepCvirAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(cirr,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(endemicCountries,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(smoke,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(diabetes,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(obese,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hemochro,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(artHyper,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(chronRenal,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hiv,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(Nasteato,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(esophVarices,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(spleno,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(portalHyper,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(portalVeinThromb,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(LiverMeta,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(RadioHallmark,transform = function(x) x + 1,
                  levels = c("no", 'yes')) 
# %>%
#   step_num2factor(numNodules,transform = function(x) x + 1,
#                   levels = as.character(0:5))

dat2 <- bake(prep(rec_base), new_data = dat)
```

# Define XGBoost model and its tuning grid to be tuned simultaneously with recipe input later 

```{r xgboost mspec} 
xgbtree_model <- TunedModel(XGBTreeModel, 
                            grid = expand_params(
                              nrounds = as.integer(c(50, 100, 150)), 
                              # number of boosting iterations 
                              eta = seq(0.1, 0.5, length = 5), 
                              # shrinkage of variable weights at each iteration to prevent overfitting 
                              max_depth = as.integer(c(4:8)) 
                              # maximum tree depth 
                              )
                            )
```

# knn, nzv, dummy, center, scale 

```{r knn none}
fnames <- paste0("./data/ModelCache/",
                 c("knn_none_xgboost_fit.RDS", "knn_none_xgboost_res.RDS"))

# remove predictor variables that have too many missing values by using step_nzv 
# use knn to impute 
# use bag to impute 
rec_knn_none <- rec_base %>%
  step_impute_knn(all_predictors(), id = "knn")  %>%
  step_nzv(all_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
  
  
  # step_impute_mode(all_nominal_predictors()) %>%
  # step_impute_mean(all_numeric_predictors()) 

rec_grid_knn_none <- expand_steps(
  knn = list(neighbors = 1:5)
) 

rec_tun_knn_none <- TunedInput(rec_knn_none, grid = rec_grid_knn_none) 

mspec_tun_knn_none <- ModelSpecification(
  rec_tun_knn_none, 
  model = xgbtree_model, 
  control = ctrl 
) %>% set_optim_bayes()
# use bayesian optimization 

# get the optimal model selected 
mlfit_knn_none <- fit(mspec_tun_knn_none) 
saveRDS(mlfit_knn_none, fnames[1])

# get resampled predictive performance 
mlres_knn_none <- resample(mspec_tun_knn_none, control = ctrl) 
saveRDS(mlres_knn_none, fnames[2])
summary(mlres_knn_none)

(tuned_model_knn_none <- as.MLModel(mlfit_knn_none)) 
summary(tuned_model_knn_none)

# variable importance 
varimp(mlfit_knn_none) %>% plot()
```

# knn, corr, nzv, dummy, center, scale 

```{r knn corr}
fnames <- paste0("./data/ModelCache/",
                 c("knn_corr_xgboost_fit.RDS", "knn_corr_xgboost_res.RDS"))

# remove predictor variables that have too many missing values by using step_nzv 
# use knn to impute 
rec_knn_corr <- rec_base %>%
  step_impute_knn(all_predictors(), id = "knn") %>%
  step_nzv(all_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  
  
  # step_impute_mode(all_nominal_predictors()) %>%
  # step_impute_mean(all_numeric_predictors()) 
  step_corr(all_numeric_predictors(), id = "corr")

rec_grid_knn_corr <- expand_steps(
  knn = list(neighbors = 1:5), 
  corr = list(threshold = c(0.75, 0.8, 0.85, 0.9))
) 

rec_tun_knn_corr <- TunedInput(rec_knn_corr, grid = rec_grid_knn_corr) 

mspec_tun_knn_corr <- ModelSpecification(
  rec_tun_knn_corr, 
  model = xgbtree_model, 
  control = ctrl 
) %>% set_optim_bayes()
# use bayesian optimization 

# get the optimal model selected 
mlfit_knn_corr <- fit(mspec_tun_knn_corr) 
saveRDS(mlfit_knn_corr, fnames[1])

# get resampled predictive performance 
mlres_knn_corr <- resample(mspec_tun_knn_corr, control = ctrl) 
saveRDS(mlres_knn_corr, fnames[2])
summary(mlres_knn_corr)

(tuned_model_knn_corr <- as.MLModel(mlfit_knn_corr)) 
summary(tuned_model_knn_corr)

# variable importance 
varimp(mlfit_knn_corr) %>% plot()
```



