---
title: "Analysis"
output: html_document
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loadPackages, message=FALSE, warning=FALSE}
library(dplyr)
library(MachineShop)
library(recipes)
library(kableExtra)
library(arsenal)
```

```{r controlSetup, results='hide', echo=FALSE}
library(doSNOW)
registerDoSNOW(makeCluster(8))
## Resample control object
ctrl <- CVControl(seed = 123)
```


```{r preProcess, echo = FALSE}
#dat <- readRDS("./data/hcc_data.RDS")
dat <- readRDS("~/Desktop/R practice/Machine learning class spring 2022/hcc-survival/hcc_data.RDS")
rec_base <- recipe(
  status ~ .,
  data = dat
) %>%
  role_case(stratum = status) %>%
  check_missing(status) %>%
  step_num2factor(status, transform = function(x) x + 1,
                  levels = c("died", "survive")) %>%
  step_num2factor(gender, transform = function(x) x + 1,
                  levels = c("female", "male")) %>%
  step_num2factor(symptom, transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(alc, transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepBsurfAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepBeAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepBcorAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hepCvirAnti,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(cirr,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(endemicCountries,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(smoke,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(diabetes,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(obese,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hemochro,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(artHyper,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(chronRenal,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(hiv,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(Nasteato,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(esophVarices,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(spleno,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(portalHyper,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(portalVeinThromb,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(LiverMeta,transform = function(x) x + 1,
                  levels = c("no", 'yes')) %>%
  step_num2factor(RadioHallmark,transform = function(x) x + 1,
                  levels = c("no", 'yes')) 
# %>%
#   step_num2factor(numNodules,transform = function(x) x + 1,
#                   levels = as.character(0:5))
dat2 <- bake(prep(rec_base), new_data = dat)
```

```{r}
## Define RandomForest model and its tuning grid to be tuend simultaneously with recipe input later
#grid.model <- TunedModel(RandomForestModel(),
                         # grid = expand_params(
                          # ntree = as.integer(c(5, 10, 15)), 
                            #number of trees to grow
                             # mtry = as.integer(c(5, 10, 15)), 
                              #number of variables rnadomly sampled as caididates at each split
                              #  nodesize = as.integer(c(1, 2, 3)),
                                #minimum size of terminal nodes
                               # maxnodes = as.integer(c(3, 5, 10))
                                #maximum number of terminal nodes trees in the forest can have. 
                        #  )
#)
## Global grid size (default parameters only)
grid.model <- TunedModel(
  RandomForestModel,
  grid = 5
)
```

```{r}
#KNN
fnames <- paste0("./data/ModelCache/",
                 c("knn_none_RForest_fit.RDS", "knn_none_RForest_res.RDS"))
# remove predictor variables that have too many missing values by using step_nzv 
# use knn to impute 
# use bag to impute 
rec_knn_none <- rec_base %>%
  step_impute_knn(all_predictors(), id = "knn")  %>%
  step_nzv(all_predictors()) %>% #trying nzv first instead of knn
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
  # step_impute_mode(all_nominal_predictors()) %>%
  # step_impute_mean(all_numeric_predictors()) 
rec_grid_knn_none <- expand_steps(
  knn = list(neighbors = 1:5)
) 
rec_tun_knn_none <- TunedInput(rec_knn_none, grid = rec_grid_knn_none) 
mspec_tun_knn_none <- ModelSpecification(
  rec_tun_knn_none, 
  model = grid.model, 
  control = ctrl 
) %>% set_optim_bayes()

mlfit_knn_none <- fit(mspec_tun_knn_none) 
#saveRDS(mlfit_knn_none, fnames[1])  

# get resampled predictive performance 
mlres_knn_none <- resample(mspec_tun_knn_none, control = ctrl) 
#saveRDS(mlres_knn_none, fnames[2])
summary(mlres_knn_none)
(tuned_model_knn_none <- as.MLModel(mlfit_knn_none)) 
summary(tuned_model_knn_none)
# variable importance 
varimp(mlfit_knn_none) %>% plot()
```

```{r}
# knn, corr, nzv, dummy, center, scale 
fnames <- paste0("./data/ModelCache/",
                 c("knn_corr_RForest_fit.RDS", "knn_corr_RForest_res.RDS"))
# remove predictor variables that have too many missing values by using step_nzv 
# use knn to impute 
rec_knn_corr <- rec_base %>%
  step_impute_knn(all_predictors(), id = "knn") %>%
  step_nzv(all_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  
  
  # step_impute_mode(all_nominal_predictors()) %>%
  # step_impute_mean(all_numeric_predictors()) 
  step_corr(all_numeric_predictors(), id = "corr")
rec_grid_knn_corr <- expand_steps(
  knn = list(neighbors = 1:5), 
  corr = list(threshold = c(0.75, 0.8, 0.85, 0.9))
) 
rec_tun_knn_corr <- TunedInput(rec_knn_corr, grid = rec_grid_knn_corr) 
mspec_tun_knn_corr <- ModelSpecification(
  rec_tun_knn_corr, 
  model = grid.model, 
  control = ctrl 
) %>% set_optim_bayes()
# use bayesian optimization 
# get the optimal model selected 
mlfit_knn_corr <- fit(mspec_tun_knn_corr) #Same issue as above
#saveRDS(mlfit_knn_corr, fnames[1])
# get resampled predictive performance 
mlres_knn_corr <- resample(mspec_tun_knn_corr, control = ctrl) 
#saveRDS(mlres_knn_corr, fnames[2])
summary(mlres_knn_corr)
(tuned_model_knn_corr <- as.MLModel(mlfit_knn_corr)) 
summary(tuned_model_knn_corr)
# variable importance 
varimp(mlfit_knn_corr) %>% plot()
```
